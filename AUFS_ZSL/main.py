# -*- coding: utf-8 -*-

import os
import numpy as np
from scipy import io as sio
import pickle
import argparse
from termcolor import cprint

import torch
import torch.nn as nn
import torch.utils.data as data
import torch.nn.functional as F
import torch.autograd as autograd
from torch.autograd import Variable
from torch.utils.data import Dataset
from torchvision import transforms
import torch.nn.init as init

from data_utils import ZSL_Dataset
from models import _netG, _netG2, _netD, Regressor
import kNN
import kNN_cosine
from ksvm import MyKSVM
from debug import visualization
from classifiers import SoftmaxClassifier


def arg_parse():
    desc = 'deep embedding model for zero-shot video classification'
    parser = argparse.ArgumentParser(description=desc)
    parser.add_argument('--mode', type=str, default='train', help='train or test')
    parser.add_argument('--dataset_name', type=str, default='cub', help='dataset name')
    parser.add_argument('--resume', type=str, default='', help='path of checkpoint file for restarting or testing')
    parser.add_argument('--n_iteration', type=int, default=10, help='how many iteration to run')
    parser.add_argument('--batch_size', type=int, default=64, help='batch size')
    parser.add_argument('--lr_G', type=float, default=1e-4, help='learning rate of G')
    parser.add_argument('--lr_D', type=float, default=1e-4, help='learning rate of D')
    parser.add_argument('--lr_R', type=float, default=1e-4, help='learning rate of R')
    parser.add_argument('--weight_decay', type=float, default=1e-2, help='weight decay')
    parser.add_argument('--optimizer', type=str, default='adam', help='which optimizer to use')
    parser.add_argument('--labelIdxStart0or1', type=int, choices=[0, 1], default=1, help='self explained')
    parser.add_argument('--root_dir', type=str, default='/media/sdb1/chenrui/journal/zeroshot/relatedwork/LearningToCompare_ZSL/data', help='root dir of data')
    parser.add_argument('--save_dir', type=str, default='./checkpoint', help='root dir for saving model')
    parser.add_argument('--all_visualFea_label_file', type=str, default='res101.mat', help='file contains both visual feature and label of whole datset')
    parser.add_argument('--auxiliary_file', type=str, default='original_att_splits.mat', help='file contains splits and semantic feature')
    parser.add_argument('--use_z', type=str, default='true', help='use noise z or not')
    parser.add_argument('--z_dim', type=int, default=100, help='dimension of noise')
    parser.add_argument('--gpuid', type=int, default=0, help='which gpu to use')
    parser.add_argument('--centroid_lambda', type=float, default=1., help='hyperparameter of centroid loss')
    parser.add_argument('--_lambda', type=float, default=0.00015, help='TODO')
    parser.add_argument('--gp_lambda', type=float, default=1., help='hyperparameter of gradient penalty')
    parser.add_argument('--regression_lambda', type=float, default=1., help='hyperparameter of semantic feature regression')
    parser.add_argument('--n_iter_D', type=int, default=5, help='iteration number of D')
    parser.add_argument('--n_iter_G', type=int, default=1, help='iteration number of G')
    parser.add_argument('--n_generation_perClass', type=int, default=50, help='how many samples will be generated by G for SVM training')
    parser.add_argument('--classifier_type', type=str, default='knn', help='what kind of classifier to use for the final unseen classification task. (e.g., knn, svm)')
    parser.add_argument('--n_epoch_sftcls', type=int, default=10, help='epochs for softmax classifier training')
    parser.add_argument('--use_pca', type=str, default='true', help='use PCA (for visual feature) or not')
    parser.add_argument('--reduced_dim_pca', type=int, default=1024, help='the dimension of visual feature after PCA')

    args = parser.parse_args()
    return args


def print_args(args):
    print('-' * 50)
    for arg, content in args.__dict__.items():
        print("{}: {}".format(arg, content))
    print('-' * 50)


def weights_init(m):
    classname = m.__class__.__name__
    if 'Linear' in classname:
        init.xavier_normal_(m.weight.data)
        init.constant_(m.bias.data, 0.0)


def calc_gradient_penalty(netD, real_data, fake_data, args):
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    alpha = torch.rand(real_data.size()[0], 1)
    alpha = alpha.expand(real_data.size())
    alpha = alpha.to(device)
    
    interpolates = alpha * real_data + ((1 - alpha) * fake_data)
    interpolates = interpolates.to(device)
    interpolates = Variable(interpolates, requires_grad=True)
    disc_interpolates, _ = netD(interpolates)

    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,
                              grad_outputs=torch.ones(disc_interpolates.size()).to(device),
                              create_graph=True, retain_graph=True, only_inputs=True)[0]
    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * args.gp_lambda
    return gradient_penalty


def reset_grad(nets):
    for net in nets:
        net.zero_grad()

def getloss(syn_vi_fea, real_vi_fea):
    loss = torch.pow(real_vi_fea - syn_vi_fea, 2).sum()
    loss /= real_vi_fea.size(0)
    return loss


def getloss_cosine(syn_vi_fea, real_vi_fea):
    assert syn_vi_fea.size(0) == real_vi_fea.size(0)
    batch_size = syn_vi_fea.size(0)
    loss = 0.
    for i in range(batch_size):
        v1_sq = torch.dot(syn_vi_fea[i, :], syn_vi_fea[i, :])
        v2_sq = torch.dot(real_vi_fea[i, :], real_vi_fea[i, :])
        dis = 1 - torch.dot(syn_vi_fea[i, :], real_vi_fea[i, :]) / (v1_sq * v2_sq).sqrt()
        loss += dis
    return loss


def nets_weights_init(nets):
    for net in nets:
        net.apply(weights_init)

def print_nets(nets):
    for net in nets:
        print(net)


def compute_accuracy(generator, test_semantic, test_visual, test_classIdx, \
                     test_videoLabel, use_z, n_gene_perC, classifier_type, \
                     n_epoch_sftcls):
    '''Evaluation'''
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    n_generation_perClass = n_gene_perC    # how many samples are generated by G per class
    nb_samples = test_visual.shape[0]
    test_semantic = torch.from_numpy(test_semantic).float().to(device)
    if use_z == 'true':
        z = torch.randn(test_semantic.size()[0], z_dim).to(device)
        syn_vi_fea = generator(test_semantic, z)
    else:
        syn_vi_fea = generator(test_semantic)
    
    ## kNN as a classifier during testing
    if classifier_type == 'knn':
        outpred = [0] * nb_samples
        test_videoLabel = test_videoLabel.astype("float32")
        for i in range(nb_samples):
            outputLabel = kNN.kNNClassify(test_visual[i, :], syn_vi_fea.cpu().data.numpy(), test_classIdx, 5)
            outpred[i] = outputLabel
        outpred = np.array(outpred)
        acc = np.equal(outpred, test_videoLabel).mean()

    ## kernel svm as a classifier during testing
    elif classifier_type == 'svm' or 'softmax':
        expend_testvideoLabel = test_classIdx
        for cnt in range(n_generation_perClass - 1):
            if use_z == 'true':
                z = torch.randn(test_semantic.size()[0], z_dim).to(device)
                temp_syn_vi_fea = generator(test_semantic, z)
            else:
                temp_syn_vi_fea = generator(test_semantic)
            syn_vi_fea = torch.cat((syn_vi_fea, temp_syn_vi_fea), dim=0)
            expend_testvideoLabel = np.hstack((expend_testvideoLabel, test_classIdx))

        assert syn_vi_fea.size(0) == expend_testvideoLabel.shape[0]
        syn_vi_fea = syn_vi_fea.cpu().detach().numpy()

        dataset_obj = dict()
        dataset_obj['tr_data' ] = syn_vi_fea
        dataset_obj['tr_label'] = expend_testvideoLabel
        dataset_obj['te_data' ] = test_visual
        dataset_obj['te_label'] = test_videoLabel
        if classifier_type == 'svm':
            ksvm = MyKSVM(dataset_obj)
            acc1 = ksvm.linear_kernel()
            acc2 = ksvm.nonlinear_kernel()     # if the degree equals to 3, may raise a MemoryError
            acc3 = ksvm.poly_kernel()
            acc4 = ksvm.RBF_kernel()
            acc  = max((acc1, acc2, acc3, acc4))
        elif classifier_type == 'softmax':
            n_class = len(test_classIdx)
            n_epoch = n_epoch_sftcls
            batch_size = -1
            lr = 1e-3
            sft_cls = fit_softmaxClassifier(n_class, dataset_obj, n_epoch, batch_size, lr)
            te_y = dataset_obj['te_label']
            global_label = set(te_y)
            globalLabel2localLabel = dict()
            for global_idx, local_idx in zip(global_label, list(range(len(global_label)))):
                globalLabel2localLabel[global_idx] = local_idx
            te_y = np.array([globalLabel2localLabel[i] for i in te_y])
            te_x = torch.from_numpy(dataset_obj['te_data']).float()
            te_y = torch.from_numpy(te_y).long()
            sft_cls.cpu()
            te_y_hat = sft_cls(te_x)
            acc = (np.argmax(te_y_hat.detach().numpy(), axis=1) == te_y.detach().numpy()).sum() / float(te_y.size()[0])

    return acc


def fit_softmaxClassifier(n_class, dataset_dict, n_epoch, batch_size, lr):
    '''Fit softmax classifier by the generated visual feature for evaluating performance.'''
    tr_x = dataset_dict['tr_data' ]
    tr_y = dataset_dict['tr_label']

    input_dim = tr_x.shape[-1]
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    sft_cls = SoftmaxClassifier(input_dim, n_class).to(device)
    sft_cls.apply(weights_init)
    sft_cls.train()
    
    optimizer = torch.optim.Adam(sft_cls.parameters(), lr=lr)
    criterion = nn.CrossEntropyLoss()

    global_label = set(tr_y)
    globalLabel2localLabel = dict()
    for global_idx, local_idx in zip(global_label, list(range(len(global_label)))):
        globalLabel2localLabel[global_idx] = local_idx
    tr_y = np.array([globalLabel2localLabel[i] for i in tr_y])
    tr_x = torch.from_numpy(tr_x).to(device).float()
    tr_y = torch.from_numpy(tr_y).to(device).long()
    for e in range(n_epoch):
        tr_y_hat = sft_cls(tr_x)
        loss = criterion(tr_y_hat, tr_y)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        tr_acc = (np.argmax(tr_y_hat.detach().cpu().numpy(), axis=1) == tr_y.detach().cpu().numpy()).sum() / float(tr_y.size()[0])

    return sft_cls



if __name__ == '__main__':
    args = arg_parse()
    print_args(args)
    os.environ['CUDA_VISIBLE_DEVICES'] = str(args.gpuid)
    mode = args.mode
    dataset_name = args.dataset_name
    labelIdxStart0or1 = args.labelIdxStart0or1
    root_dir = args.root_dir
    all_visualFea_label_file = args.all_visualFea_label_file
    auxiliary_file = args.auxiliary_file
    batch_size = args.batch_size
    lr_G = args.lr_G
    lr_D = args.lr_D
    lr_R = args.lr_R
    weight_decay = args.weight_decay
    n_iter_D = args.n_iter_D
    n_iter_G = args.n_iter_G
    use_pca = args.use_pca
    reduced_dim_pca = args.reduced_dim_pca

    zsl_dataset = ZSL_Dataset(root_dir, dataset_name, mode, all_visualFea_label_file, auxiliary_file, use_pca, reduced_dim_pca)
    zsl_dataloader = data.DataLoader(zsl_dataset, batch_size=batch_size, shuffle=True, num_workers=4)
    print('data is ready!')

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    vi_fea_dim = zsl_dataset.vis_fea_dim
    se_fea_dim = zsl_dataset.sem_fea_dim
    n_tr_class = zsl_dataset.n_tr_class
    z_dim = args.z_dim
    if args.use_z.lower() == 'true':
        netG = _netG(se_fea_dim, vi_fea_dim, z_dim).to(device)
    else:
        netG = _netG2(se_fea_dim, vi_fea_dim).to(device)
    netD = _netD(vi_fea_dim, n_tr_class).to(device)
    netR = Regressor(vi_fea_dim, se_fea_dim).to(device)
    nets = [netG, netD, netR]
    nets_weights_init(nets)
    print_nets(nets)

    te_data_unseen, te_data_seen = zsl_dataset.get_testData()
    te_vis_fea_unseen, te_sem_fea_unseen, te_label_unseen, te_labelID_unseen, te_sem_fea_pro_unseen = te_data_unseen
    te_vis_fea_seen, te_sem_fea_seen, te_label_seen, te_labelID_seen, te_sem_fea_pro_seen = te_data_seen
    tr_vis_fea, tr_sem_fea, all_tr_label, tr_labelID, tr_sem_fea_pro = zsl_dataset.get_trainData()

    tr_cls_centroid = zsl_dataset.get_tr_centroid()
    tr_cls_centroid = torch.from_numpy(tr_cls_centroid).to(device)

    which_optimizer = args.optimizer.lower()
    assert which_optimizer in ['adam', 'sgd', 'rmsprop']
    if  which_optimizer == 'adam':
        optimizer_G = torch.optim.Adam(netG.parameters(), lr=lr_G, weight_decay=weight_decay)
        optimizer_D = torch.optim.Adam(netD.parameters(), lr=lr_D, weight_decay=weight_decay)
        optimizer_R = torch.optim.Adam(netR.parameters(), lr=lr_R, weight_decay=weight_decay)
    elif which_optimizer == 'sgd':
        optimizer_G = torch.optim.SGD(netG.parameters(), lr=lr_G, weight_decay=weight_decay)
        optimizer_D = torch.optim.SGD(netD.parameters(), lr=lr_D, weight_decay=weight_decay)
        optimizer_R = torch.optim.SGD(netR.parameters(), lr=lr_R, weight_decay=weight_decay)
    elif which_optimizer == 'rmsprop':
        optimizer_G = torch.optim.RMSprop(netG.parameters(), lr=lr_G, weight_decay=weight_decay)
        optimizer_D = torch.optim.RMSprop(netD.parameters(), lr=lr_D, weight_decay=weight_decay)
        optimizer_R = torch.optim.RMSprop(netR.parameters(), lr=lr_R, weight_decay=weight_decay)
    

    # regression_criterion = nn.MSELoss()
    regression_criterion = nn.L1Loss()

    save_subdir = dataset_name
    save_dir = os.path.join(args.save_dir, save_subdir)
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)

    best_acc_unseen = 0
    best_acc_seen = 0
    data_iterator = enumerate(zsl_dataloader)
    for i in range(args.n_iteration):
        '''updata discriminator'''
        for _ in range(n_iter_D):
            try:
                step, (vi_fea, se_fea, tr_label) = next(data_iterator)
            except StopIteration:
                data_iterator = enumerate(zsl_dataloader)
                step, (vi_fea, se_fea, tr_label) = next(data_iterator)

            X_real = vi_fea.to(device)
            se_fea = se_fea.to(device)
            y_true = tr_label.to(device)
            z = torch.randn(se_fea.size()[0], z_dim).to(device)

            reset_grad(nets)

            ## GAN's D loss
            D_real, C_real = netD(X_real)   # `C` here means `classification`
            D_loss_real = torch.mean(D_real)
            C_loss_real = F.cross_entropy(C_real, y_true)
            DC_loss = -D_loss_real + C_loss_real
            DC_loss.backward(retain_graph=True)     # for `Wasserstein_D.backward()` below.

            ## GAN's G loss
            if args.use_z.lower() == 'true':
                X_fake = netG(se_fea, z)
            else:
                X_fake = netG(se_fea)
            D_fake, C_fake = netD(X_fake)
            D_loss_fake = torch.mean(D_fake)
            C_loss_fake = F.cross_entropy(C_fake, y_true)
            DC_loss = D_loss_fake + C_loss_fake
            DC_loss.backward(retain_graph=True)

            ## train with gradient penalty (WGAN_GP)
            grad_penalty = calc_gradient_penalty(netD, X_real.data, X_fake.data, args)
            grad_penalty.backward()

            Wasserstein_D = D_loss_real - D_loss_fake
            Wasserstein_D.backward()
            optimizer_D.step()

        '''update generator'''
        for _ in range(n_iter_G):
            try:
                step, (vi_fea, se_fea, tr_label) = next(data_iterator)
            except StopIteration:
                data_iterator = enumerate(zsl_dataloader)
                step, (vi_fea, se_fea, tr_label) = next(data_iterator)

            X_real = vi_fea.to(device)
            se_fea = se_fea.to(device)
            y_true = tr_label.to(device)
            z = torch.randn(se_fea.size()[0], z_dim).to(device)

            if args.use_z.lower() == 'true':
                X_fake = netG(se_fea, z)
            else:
                X_fake = netG(se_fea)
            D_fake, C_fake = netD(X_fake)
            __    , C_real = netD(X_real)

            ## GAN's G loss
            G_loss = torch.mean(D_fake)
            ## Auxiliary classification loss
            C_loss = (F.cross_entropy(C_real, y_true) + F.cross_entropy(C_fake, y_true)) / 2
            
            GC_loss = -G_loss + C_loss

            # centroid loss
            centroid_loss = torch.FloatTensor([0.0]).to(device)
            for j in range(n_tr_class):
                current_tr_classIdx = zsl_dataset.tr_classIdx_map[zsl_dataset.tr_labelID[j]]
                sample_idx = (y_true == current_tr_classIdx).data.nonzero().squeeze()   # get the index of the current training class
                if sample_idx.numel() != 0:
                    fake_sample_of_current_class = X_fake[sample_idx, :]
                    centroid_loss += (fake_sample_of_current_class.mean(dim=0) - tr_cls_centroid[j]).pow(2).sum().sqrt()
            centroid_loss *= 1.0 / n_tr_class * args.centroid_lambda
            
            ## semantic feature regression loss
            fake_semantic_regression = netR(X_fake)
            assert fake_semantic_regression.size() == se_fea.size()
            regrs_loss = regression_criterion(fake_semantic_regression, se_fea) * args.regression_lambda

            
            loss1 = getloss(X_fake, X_real)
            loss2 = getloss_cosine(X_fake, X_real)
            _loss = args._lambda * loss1 + loss2

            reset_grad(nets)

            total_loss = GC_loss + centroid_loss + _loss + regrs_loss
            total_loss.backward()

            optimizer_G.step()
            optimizer_R.step()

        if i % 10 == 0 and i != 0:
            acc_real = (np.argmax(C_real.data.cpu().numpy(), axis=1) == y_true.data.cpu().numpy()).sum() / float(y_true.data.size()[0])
            acc_fake = (np.argmax(C_fake.data.cpu().numpy(), axis=1) == y_true.data.cpu().numpy()).sum() / float(y_true.data.size()[0])

            if acc_fake > 0.:
                unseen_acc = 100 * compute_accuracy(netG, te_sem_fea_pro_unseen, te_vis_fea_unseen, te_labelID_unseen, te_label_unseen, args.use_z.lower(), args.n_generation_perClass, args.classifier_type, args.n_epoch_sftcls)
                seen_acc = 100 * compute_accuracy(netG, te_sem_fea_pro_seen, te_vis_fea_seen, te_labelID_seen, te_label_seen, args.use_z.lower(), args.n_generation_perClass, args.classifier_type, args.n_epoch_sftcls)
                acc_tr = 100 * compute_accuracy_debug(netG, tr_sem_fea_pro, tr_vis_fea, tr_labelID, all_tr_label, args.use_z.lower(), args.n_generation_perClass, args.classifier_type, args.n_epoch_sftcls)
            else:
                unseen_acc = -1
                seen_acc = -1
                acc_tr = -1

            print('It%5d  Was_D:%6.2lf  cen_ls:%5.2lf  rgs_ls:%5.3lf  G_ls:%6.3lf  C_ls:%5.3lf  D_ls_real:%6.3lf  C_ls_real:%5.3lf  D_ls_fake:%6.3lf  C_ls_fake:%5.3lf  _ls:%6.3lf  tr_real_a:%4.2lf tr_fake_a:%4.2lf uns_a: %.2lf  s_a: %.2lf  a_tr: %.2lf' \
                  % (i, Wasserstein_D.item(), centroid_loss.item(), args.regression_lambda * regrs_loss.item(), G_loss.item(), C_loss.item(), D_loss_real.item(), C_loss_real.item(), D_loss_fake.item(), C_loss_fake.item(), _loss.item(), acc_real, acc_fake, unseen_acc, seen_acc, acc_tr))

            if unseen_acc > best_acc_unseen:
                best_acc_unseen = unseen_acc
                best_acc_seen = seen_acc if seen_acc > best_acc_seen else best_acc_seen
                save_dict = {
                    'iteration': (i + 1),
                    'netG_state_dict': netG.state_dict(),
                    'netD_state_dict': netD.state_dict(),
                    'netR_state_dict': netR.state_dict(),
                    'acc_unseen': best_acc_unseen,
                    'acc_seen': best_acc_seen,
                }
                checkpoint_name = 'gan_checkpoint_' + dataset_name + '_iter' + str(i + 1) + '_accUnseen%.2lf_accSeen%.2lf.pkl' % (best_acc_unseen, best_acc_seen)
                checkpoint_path = os.path.join(save_dir, checkpoint_name)
                cprint('saving ' + checkpoint_name + ' in ' + save_dir + '...', 'green')
                torch.save(save_dict, checkpoint_path)